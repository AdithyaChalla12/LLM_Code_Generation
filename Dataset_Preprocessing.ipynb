{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cloning Dataset  - API Pack and Storing it in google drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/datasets/apipack/API-Pack-Dataset\n",
        "\n",
        "\n",
        "src = '/content/API-Pack-Dataset'\n",
        "dst = '/content/drive/MyDrive/API-Pack-Dataset'\n",
        "\n",
        "shutil.move(src, dst)\n",
        "\n",
        "print(\"Dataset successfully saved to your Google Drive at:\", dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QBvY-u6wms6",
        "outputId": "5e4b314b-9a02-49b2-f65e-6880ae96740e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Git LFS initialized.\n",
            "Cloning into 'API-Pack-Dataset'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 35 (delta 3), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (35/35), 9.46 KiB | 1.58 MiB/s, done.\n",
            "Filtering content: 100% (10/10), 3.14 GiB | 255.43 MiB/s, done.\n",
            "✅ Dataset successfully saved to your Google Drive at: /content/drive/MyDrive/API-Pack-Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Pack dataset has APIs in different languages such as python, javascript, java, ruby, go, swift and so on. Our team intends to work on the python data primarily for this task\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/API-Pack-Dataset\"\n",
        "OUT_MAIN = f\"{DATASET_DIR}/api_pack_training.jsonl\"\n",
        "\n",
        "\n",
        "SUB_DIR = f\"{DATASET_DIR}/langs\"\n",
        "os.makedirs(SUB_DIR, exist_ok=True)\n",
        "\n",
        "files = glob.glob(f\"{DATASET_DIR}/total_data_cleaned_*.json\")\n",
        "print(\"Found files:\", files)\n",
        "\n",
        "def clean_text(t):\n",
        "    if t is None:\n",
        "        return \"\"\n",
        "    return t.strip()\n",
        "\n",
        "# Creating input and output pairs needed for finetuning. For this we are using concatenating instruction, language of api call,, functionality of the api, api arguments, description, domain and path available\n",
        "# in the dataset as prompt to the large language model.\n",
        "\n",
        "def process_single_item(ex):\n",
        "    api_call_data = ex.get(\"api_call_data\", {})\n",
        "\n",
        "    input_obj = {\n",
        "        \"instruction\": clean_text(ex.get(\"instruction\", \"\")),\n",
        "        \"lang\": clean_text(api_call_data.get(\"lang\", \"\")),\n",
        "        \"functionality\": clean_text(api_call_data.get(\"functionality\", \"\")),\n",
        "        \"api_arguments\": api_call_data.get(\"api_arguments\", {}),\n",
        "        \"description\": clean_text(api_call_data.get(\"description\", \"\")),\n",
        "        \"domain\": api_call_data.get(\"domain\", []),\n",
        "        \"path\": clean_text(api_call_data.get(\"path\", \"\")),\n",
        "    }\n",
        "\n",
        "    output_obj = {\n",
        "        \"api_call\": clean_text(api_call_data.get(\"api_call\", \"\")),\n",
        "    }\n",
        "\n",
        "    return {\"input\": input_obj, \"output\": output_obj}\n",
        "\n",
        "\n",
        "all_rows = []\n",
        "lang_groups = {}\n",
        "for fpath in files:\n",
        "    print(\"Processing:\", fpath)\n",
        "\n",
        "    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for ex in data:\n",
        "        row = process_single_item(ex)\n",
        "        all_rows.append(row)\n",
        "\n",
        "        lang = row[\"input\"][\"lang\"]\n",
        "        if lang not in lang_groups:\n",
        "            lang_groups[lang] = []\n",
        "        lang_groups[lang].append(row)\n",
        "\n",
        "\n",
        "print(\"Total processed samples:\", len(all_rows))\n",
        "\n",
        "\n",
        "with open(OUT_MAIN, \"w\", encoding=\"utf-8\") as f:\n",
        "    for row in all_rows:\n",
        "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"Saved main training dataset →\", OUT_MAIN)\n",
        "\n",
        "\n",
        "for lang, rows in lang_groups.items():\n",
        "    safe_lang = lang.lower().replace(\" \", \"_\")\n",
        "    out_path = f\"{SUB_DIR}/api_pack_{safe_lang}.jsonl\"\n",
        "\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for row in rows:\n",
        "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    print(f\"Saved {lang} dataset → {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogqhHSrPxKwp",
        "outputId": "67ad4c6d-7ff8-4497-e026-11c135db953b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: ['/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_java.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_libcurl.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_node.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_ruby.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_go.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_javascript.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_php.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_swift.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_curl.json', '/content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_python.json']\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_java.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_libcurl.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_node.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_ruby.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_go.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_javascript.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_php.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_swift.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_curl.json\n",
            "Processing: /content/drive/MyDrive/API-Pack-Dataset/total_data_cleaned_python.json\n",
            "Total processed samples: 1014093\n",
            "Saved main training dataset → /content/drive/MyDrive/API-Pack-Dataset/api_pack_training.jsonl\n",
            "Saved Java dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_java.jsonl\n",
            "Saved java dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_java.jsonl\n",
            "Saved libcurl dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_libcurl.jsonl\n",
            "Saved Node dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_node.jsonl\n",
            "Saved node dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_node.jsonl\n",
            "Saved Ruby dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_ruby.jsonl\n",
            "Saved ruby dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_ruby.jsonl\n",
            "Saved go dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_go.jsonl\n",
            "Saved Go dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_go.jsonl\n",
            "Saved javascript xhr dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_javascript_xhr.jsonl\n",
            "Saved PHP dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_php.jsonl\n",
            "Saved swift dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_swift.jsonl\n",
            "Saved Swift dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_swift.jsonl\n",
            "Saved cURL dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_curl.jsonl\n",
            "Saved curl dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_curl.jsonl\n",
            "Saved Python dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_python.jsonl\n",
            "Saved python dataset → /content/drive/MyDrive/API-Pack-Dataset/langs/api_pack_python.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIjjhzY6yW-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}